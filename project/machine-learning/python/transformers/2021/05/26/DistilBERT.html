<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Authorship Identification - Part-2 (DistilBERT Transformer) | Keen Eye &amp; Data</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Authorship Identification - Part-2 (DistilBERT Transformer)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Using transfer-learning to fine-tune pretrained DistilBERT transformer for authorship identification. In a nutshell, DistilBERT is a small version of BERT which is smaller, faster, cheaper, and lighter. It has 40% less parameters original BERT, runs 60% faster and preserve over 95% of BERT’s performances." />
<meta property="og:description" content="Using transfer-learning to fine-tune pretrained DistilBERT transformer for authorship identification. In a nutshell, DistilBERT is a small version of BERT which is smaller, faster, cheaper, and lighter. It has 40% less parameters original BERT, runs 60% faster and preserve over 95% of BERT’s performances." />
<link rel="canonical" href="https://www.ashishdev.codes/project/machine-learning/python/transformers/2021/05/26/DistilBERT.html" />
<meta property="og:url" content="https://www.ashishdev.codes/project/machine-learning/python/transformers/2021/05/26/DistilBERT.html" />
<meta property="og:site_name" content="Keen Eye &amp; Data" />
<meta property="og:image" content="https://www.ashishdev.codes/images/vignette/huggingface.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-26T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://www.ashishdev.codes/project/machine-learning/python/transformers/2021/05/26/DistilBERT.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.ashishdev.codes/project/machine-learning/python/transformers/2021/05/26/DistilBERT.html"},"headline":"Authorship Identification - Part-2 (DistilBERT Transformer)","dateModified":"2021-05-26T00:00:00-05:00","datePublished":"2021-05-26T00:00:00-05:00","image":"https://www.ashishdev.codes/images/vignette/huggingface.png","description":"Using transfer-learning to fine-tune pretrained DistilBERT transformer for authorship identification. In a nutshell, DistilBERT is a small version of BERT which is smaller, faster, cheaper, and lighter. It has 40% less parameters original BERT, runs 60% faster and preserve over 95% of BERT’s performances.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://www.ashishdev.codes/feed.xml" title="Keen Eye &amp; Data" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','G-XT571VSXT6','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Keen Eye &amp; Data</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Authorship Identification - Part-2 (DistilBERT Transformer)</h1><p class="page-description">Using transfer-learning to fine-tune pretrained DistilBERT transformer for authorship identification. In a nutshell, DistilBERT is a small version of BERT which is smaller, faster, cheaper, and lighter. It has 40% less parameters original BERT, runs 60% faster and preserve over 95% of BERT’s performances.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-05-26T00:00:00-05:00" itemprop="datePublished">
        May 26, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#project">project</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#machine-learning">machine-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#transformers">transformers</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/ashudva/KED/tree/master/_notebooks/2021-5-24-DistilBERT.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/ashudva/KED/master?filepath=_notebooks%2F2021-5-24-DistilBERT.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/ashudva/KED/blob/master/_notebooks/2021-5-24-DistilBERT.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-5-24-DistilBERT.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Abstract">Abstract<a class="anchor-link" href="#Abstract"> </a></h1><p><strong>This is a follow-up post on the authorship identification project.</strong><br />
I regard the past few years as the inception of the era of Transformers which started with the popular Research Paper "Attention is all you need" by "somebody" in 2020. Several transformer architectures have shown up since then. Some of the famous ones are - GPT, GPT2, and the latest GPT3 which has outperformed many previous state-of-the-art models at several tasks in NLP, BERT (by Google) is also one of the most popular transformers out there.<br />
Transformers are very large models with multi-billions of parameters. Pretrained transformers have shown tremendous capability when used with a downstream task head in Transfer Learning similar to the CNNs in Computer Vision.<br />
In this part, I'll use fine-tuned DistilBERT transformer which is a smaller version of the original BERT for the downstream classification task.<br />
I'll use the <code>transformers</code> library from Huggingface which consists of numerous state-of-the-art transformers and supports several downstream tasks out of the box. In short, I consider Huggingface a great starting point for a person engrossed in NLP and it offers tons of great functionalities.<br />
I'll provide links to resources for you to learn more about these technologies.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">plot_history</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">text_dataset_from_directory</span>

<span class="n">ds_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;data/C50/&#39;</span><span class="p">)</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="n">ds_dir</span> <span class="o">/</span> <span class="s1">&#39;train&#39;</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="n">ds_dir</span> <span class="o">/</span> <span class="s1">&#39;test&#39;</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>


<span class="n">train_ds</span> <span class="o">=</span> <span class="n">text_dataset_from_directory</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span>
                                     <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">,</span>
                                     <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                                     <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                     <span class="n">subset</span><span class="o">=</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>

<span class="n">val_ds</span> <span class="o">=</span> <span class="n">text_dataset_from_directory</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span>
                                      <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">,</span>
                                      <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                                      <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                      <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                     <span class="n">subset</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">)</span>

<span class="n">test_ds</span> <span class="o">=</span> <span class="n">text_dataset_from_directory</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span>
                                       <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">,</span>
                                       <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                                       <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                       <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">class_names</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">class_names</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">prepare_batched</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DistilBertTokenizerFast</span>

<span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">DistilBertTokenizerFast</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;distilbert-base-uncased&#39;</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">prepare_batched</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">prepare_batched</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">prepare_batched</span><span class="p">(</span><span class="n">test_ds</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFAutoModelForSequenceClassification</span>
<span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TFAutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s1">&#39;distilbert-base-uncased&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">plot_history</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="s1">&#39;sparse_categorical_accuracy&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;DistilBERT_finetuned.h5&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluate the model on test dataset&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ashudva/KED"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/project/machine-learning/python/transformers/2021/05/26/DistilBERT.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Keen Eye &amp; Data, to be a perspicacious Data Scientist</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/ashudva" title="ashudva"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/seriouscapy" title="seriouscapy"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
